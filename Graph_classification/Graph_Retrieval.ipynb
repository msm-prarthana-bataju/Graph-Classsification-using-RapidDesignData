{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing...\n",
      "Finished Importing\n"
     ]
    }
   ],
   "source": [
    "print(\"Importing...\")\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "from GCN import *\n",
    "from Utils.math_distances import cosine_distance\n",
    "from Utils.my_utils import *\n",
    "from Utils.util import *\n",
    "from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "import os\n",
    "import time\n",
    "from train_utils import get_batch_data\n",
    "from train_utils import *\n",
    "\n",
    "torch.manual_seed(124)\n",
    "np.random.seed(124)\n",
    "\n",
    "print(\"Finished Importing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings\n",
      "Using model at path: D:/3DStepGraphClassification_RapidDesignData/Datasets/RapidPrototype_TestData/GCN_model_02-16_100/Models/GCN_model_02-16\n",
      "The calculations will be performed on the device: cuda:0\n",
      "Results will be saved in: D:/3DStepGraphClassification/Output\n"
     ]
    }
   ],
   "source": [
    "print(\"Settings\")\n",
    "\n",
    "run_folder=\"../\"\n",
    "dataset = \"RPDatasets\"\n",
    "STEP_dataset = \"D:/3DStepGraphClassification_RapidDesignData/Datasets/RapidPrototype_TestData/StepData/\"\n",
    "graphml_dataset = \"D:/3DStepGraphClassification_RapidDesignData/Datasets/RapidPrototype_TestData/GraphData/\"\n",
    "learning_rate=0.0005\n",
    "batch_size=1\n",
    "num_epochs=1\n",
    "dropout=0.5\n",
    "model_name = \"GCN_model_02-16\" # \"Name of the model trained in train files\"\n",
    "model_path = \"D:/3DStepGraphClassification_RapidDesignData/Datasets/RapidPrototype_TestData/GCN_model_02-16_100/Models/\" + model_name\n",
    "\n",
    "print(\"Using model at path:\", model_path)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"The calculations will be performed on the device:\", device)\n",
    "\n",
    "# save paths\n",
    "out_dir = \"D:/3DStepGraphClassification/Output\"\n",
    "print(\"Results will be saved in:\", out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Graph data...\n",
      "# training graphs:  405\n",
      "# validation graphs:  45\n",
      "# test graphs:  50\n",
      "Loading data... finished!\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Graph data...\")\n",
    "use_degree_as_tag = False\n",
    "fold = 0\n",
    "# graphs, num_classes, filenames = my_load_data_with_filename(graphml_dataset, use_degree_as_tag)\n",
    "graphs, num_classes = my_load_data_without_graph_load(graphml_dataset)\n",
    "filenames = extract_filenames(graphs)\n",
    "\n",
    "train_graphs, test_graphs = separate_data_new(graphs, split_size=0.1)\n",
    "train_graphs, valid_graphs = separate_data_new(train_graphs, split_size=0.1)\n",
    "print(\"# training graphs: \", len(train_graphs))\n",
    "# print_data_commposition(train_graphs)\n",
    "print(\"# validation graphs: \", len(valid_graphs))\n",
    "# print_data_commposition(valid_graphs)\n",
    "print(\"# test graphs: \", len(test_graphs))\n",
    "# print_data_commposition(test_graphs)\n",
    "\n",
    "# feature_dim_size = graphs[0].node_features.shape[1]\n",
    "feature_dim_size = 64\n",
    "print(\"Loading data... finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for GCN_CN_v4:\n\tsize mismatch for scoring_layer.weight: copying a param with shape torch.Size([393, 32]) from checkpoint, the shape in current model is torch.Size([5, 32]).\n\tsize mismatch for scoring_layer.bias: copying a param with shape torch.Size([393]) from checkpoint, the shape in current model is torch.Size([5]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m GCN_CN_v4(feature_dim_size\u001b[38;5;241m=\u001b[39mfeature_dim_size, num_classes\u001b[38;5;241m=\u001b[39mnum_classes, dropout\u001b[38;5;241m=\u001b[39mdropout)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m children_counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n,c \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_children():\n",
      "File \u001b[1;32mc:\\Users\\Prarthana_Bataju.JP_MISUMI\\Anaconda3\\envs\\3D_STEP_Classification\\lib\\site-packages\\torch\\nn\\modules\\module.py:1497\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   1492\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   1493\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1494\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 1497\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1498\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   1499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for GCN_CN_v4:\n\tsize mismatch for scoring_layer.weight: copying a param with shape torch.Size([393, 32]) from checkpoint, the shape in current model is torch.Size([5, 32]).\n\tsize mismatch for scoring_layer.bias: copying a param with shape torch.Size([393]) from checkpoint, the shape in current model is torch.Size([5])."
     ]
    }
   ],
   "source": [
    "print(\"Creating model\")\n",
    "\n",
    "num_classes = 393\n",
    "# model = GCN_CN_v4(feature_dim_size=feature_dim_size, num_classes=num_classes, dropout=dropout).to(device)\n",
    "model = GCN_CN_v4(feature_dim_size=feature_dim_size, num_classes=num_classes, dropout=dropout).to(device)\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "children_counter = 0\n",
    "for n,c in model.named_children():\n",
    "    print(\"Children Counter: \",children_counter,\" Layer Name: \",n,)\n",
    "    children_counter+=1\n",
    "output_layer = \"attention\"\n",
    "\n",
    "class feature_extractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pretrained = model\n",
    "        self.pretrained.eval()\n",
    "\n",
    "        self.net = list(self.pretrained.children())[:]#-2\n",
    "        self.pretrained = None\n",
    "\n",
    "    def forward(self, adj, features):\n",
    "        features = self.net[0](x=features, edge_index=adj)\n",
    "        features = nn.functional.relu(features)\n",
    "        features = self.net[1](x=features, edge_index=adj)\n",
    "        features = nn.functional.relu(features)\n",
    "        features = self.net[2](x=features, edge_index=adj)\n",
    "        features = nn.functional.relu(features)\n",
    "        scores = self.net[3](features)\n",
    "        scores = torch.t(scores)\n",
    "\n",
    "        scores = nn.functional.relu(self.net[4](scores))\n",
    "        scores = self.net[5](scores)\n",
    "        scores = F.log_softmax(scores, dim=1)\n",
    "        return scores\n",
    "\n",
    "\n",
    "retrieval_model = feature_extractor()\n",
    "retrieval_model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 10)\n",
      "Mean time: 0.00310311484336853\n"
     ]
    }
   ],
   "source": [
    "num_graphs = len(graphs)\n",
    "# Get the size of the feature we are using\n",
    "feat_size = output_shape = num_classes\n",
    "# Preallocate the matrix for storing all the features\n",
    "all_feats = np.zeros((num_graphs, feat_size))\n",
    "times = []\n",
    "with torch.no_grad():\n",
    "    idx = np.arange(num_graphs)\n",
    "    for i in range(0, len(graphs), batch_size):\n",
    "        sampled_idx = idx[i:i + batch_size]\n",
    "        if len(sampled_idx) == 0:\n",
    "            continue\n",
    "        batch_all_graphs = [graphs[j] for j in sampled_idx]\n",
    "        all_X_concat, all_graph_labels, all_adj = get_batch_data(batch_all_graphs, device)\n",
    "        start_time = time.time()\n",
    "        features = retrieval_model(all_adj, all_X_concat)\n",
    "\n",
    "        times.append(time.time()-start_time)\n",
    "\n",
    "        all_feats[i] = np.array(features.cpu())\n",
    "print(all_feats.shape)\n",
    "\n",
    "print(\"Mean time:\", np.mean(np.array(times)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "num_queries = len(test_graphs)\n",
    "# Preallocate the matrix for storing all the features for the queries\n",
    "query_feats = np.zeros((num_queries, feat_size))\n",
    "i = 0\n",
    "with torch.no_grad():\n",
    "    idx = np.arange(num_queries)\n",
    "    for i in range(0, len(test_graphs), batch_size):\n",
    "        sampled_idx = idx[i:i + batch_size]\n",
    "        if len(sampled_idx) == 0:\n",
    "            continue\n",
    "        batch_test_graphs = [test_graphs[j] for j in sampled_idx]\n",
    "        test_X_concat, test_graph_labels, test_adj = get_batch_data(batch_test_graphs, device=device)\n",
    "        features = retrieval_model(test_adj, test_X_concat)\n",
    "        query_feats[i] = np.array(features.cpu())\n",
    "print(query_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "metric = \"cosine\"\n",
    "nbrs = NearestNeighbors(n_neighbors=num_graphs, algorithm ='auto', metric=metric).fit(all_feats)\n",
    "distances, indices = nbrs.kneighbors(query_feats)\n",
    "\n",
    "print(distances.shape)\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#this function create a perfect ranking :)\n",
    "def make_perfect_holidays_result(graphs, q_ids):\n",
    "    perfect_idx =[]\n",
    "    for qimno in q_ids:\n",
    "        this_g = graphs[qimno]\n",
    "        positive_results = set([i for i, gh in enumerate(graphs) if (gh.label == this_g.label)])\n",
    "        ok=[qimno]+[i for i in  positive_results]\n",
    "        others = [i for i in range(1491) if i not in positive_results and i != qimno]\n",
    "        perfect_idx.append(ok+others)\n",
    "    return np.array(perfect_idx)\n",
    "\n",
    "def mAP(q_ids, idx, plot=False):\n",
    "    aps = []\n",
    "    precision_recall_x_class = {}\n",
    "    for qimno, qres in zip(q_ids, idx):\n",
    "        this_g = graphs[qimno]\n",
    "        # collect the positive results in the dataset\n",
    "        # the positives have the same prefix as the query image\n",
    "        positive_results = set([i for i, gh in enumerate(graphs) if (gh.label == this_g.label)])\n",
    "        #\n",
    "        # ranks of positives. We skip the result #0, assumed to be the query image\n",
    "        ranks = [i for i, res in enumerate(qres[1:]) if res in positive_results]\n",
    "        #\n",
    "        # accumulate trapezoids with this basis\n",
    "        recall_step = 1.0 / len(positive_results)\n",
    "        ap = 0\n",
    "\n",
    "        for ntp, rank in enumerate(ranks):\n",
    "            # ntp = nb of true positives so far\n",
    "            # rank = nb of retrieved items so far\n",
    "            # y-size on left side of trapezoid:\n",
    "            precision_0 = ntp/float(rank) if rank > 0 else 1.0\n",
    "            # y-size on right side of trapezoid:\n",
    "            precision_1 = (ntp + 1) / float(rank + 1)\n",
    "            ap += (precision_1 + precision_0) * recall_step / 2.0\n",
    "\n",
    "        aps.append(ap)\n",
    "\n",
    "    return np.mean(aps)\n",
    "\n",
    "query_imids = []\n",
    "test_names = [g.name_graph for g in test_graphs]\n",
    "for i, g in enumerate(graphs):\n",
    "    if g.name_graph in test_names:\n",
    "        query_imids.append(i)\n",
    "\n",
    "perfect_result = make_perfect_holidays_result(graphs, query_imids)\n",
    "p_map = mAP(query_imids,perfect_result)\n",
    "print('Perfect mean AP = %.3f'%p_map)\n",
    "map = mAP(query_imids, indices, True)\n",
    "print('mean AP = %.3f'%map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(out_dir + \"/mAP_retrival.txt\", 'a') as f:\n",
    "    if isinstance(metric, str):\n",
    "        metric_name = metric\n",
    "    else:\n",
    "        metric_name = metric.__name__\n",
    "    f.write(\"Model: \"+ str(model.__class__.__name__) + \", metric: \"+ metric_name + \", out_layer dim:\" + str(output_shape) + \", mAP: \"+ str(map)+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3D_STEP_Classification",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "370c758caa2e141d4b1131efd09c6c2406d9069e2d89b99791a405daf105ff59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
